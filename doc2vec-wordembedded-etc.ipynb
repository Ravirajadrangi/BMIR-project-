{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import classes\n",
    "from random import shuffle\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_labels(fname, nums=False):\n",
    "    arr = []\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for line in enumerate(f):\n",
    "            s = line[1].decode('utf-8')\n",
    "            if nums:\n",
    "                yield line[1].decode('utf-8')\n",
    "            else:\n",
    "                if \"UNK\" in s:\n",
    "                    yield 3\n",
    "                elif \"NON\" in s:\n",
    "                    yield 2\n",
    "                elif \"PAST\" in s:\n",
    "                    yield 1\n",
    "                else:\n",
    "                    yield 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nums = list(read_labels(\"labels-train.txt\"))\n",
    "test_nums = list(read_labels(\"labels-test.txt\"))\n",
    "train_labels = list(read_labels(\"labels-train.txt\", nums=True))\n",
    "test_labels = list(read_labels(\"labels-test.txt\", nums=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.smart_open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(\"smoking-train.txt\"))\n",
    "test_corpus = list(read_corpus(\"smoking-test.txt\",tokens_only=True))\n",
    "model = gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, iter=55)\n",
    "model.build_vocab(train_corpus)\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = model.docvecs\n",
    "test_vecs = []\n",
    "for elem in test_corpus:\n",
    "    a = list(model.infer_vector(elem))\n",
    "    test_vecs.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(train_vecs, label=train_nums)\n",
    "xg_test = xgb.DMatrix(test_vecs, label=test_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['max_depth'] = 2\n",
    "param['eta'] = 1\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 4\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 5\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "pred = bst.predict(xg_test)\n",
    "error_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))\n",
    "\n",
    "# do the same thing again, but output probabilities\n",
    "param['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# Note: this convention has been changed since xgboost-unity\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "pred_prob = bst.predict(xg_test).reshape(test_Y.shape[0], 6)\n",
    "pred_label = np.argmax(pred_prob, axis=1)\n",
    "error_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n",
    "print('Test error using softprob = {}'.format(error_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
