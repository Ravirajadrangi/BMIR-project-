{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import classes\n",
    "from random import shuffle\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_labels(fname, nums=False):\n",
    "    arr = []\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for line in enumerate(f):\n",
    "            s = line[1].decode('utf-8')\n",
    "            if nums:\n",
    "                yield line[1].decode('utf-8')\n",
    "            else:\n",
    "                if \"UNK\" in s:\n",
    "                    yield 3\n",
    "                elif \"NON\" in s:\n",
    "                    yield 2\n",
    "                elif \"PAST\" in s:\n",
    "                    yield 1\n",
    "                else:\n",
    "                    yield 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nums = list(read_labels(\"labels-train.txt\"))\n",
    "test_nums = list(read_labels(\"labels-test.txt\"))\n",
    "train_labels = list(read_labels(\"labels-train.txt\", nums=True))\n",
    "test_labels = list(read_labels(\"labels-test.txt\", nums=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.smart_open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 1.61 s, total: 1min 9s\n",
      "Wall time: 30.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22380916"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus = list(read_corpus(\"smoking-train.txt\"))\n",
    "test_corpus = list(read_corpus(\"smoking-test.txt\",tokens_only=True))\n",
    "model = gensim.models.doc2vec.Doc2Vec(size=100, min_count=2, iter=55)\n",
    "model.build_vocab(train_corpus)\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vecs = model.docvecs\n",
    "test_vecs = []\n",
    "for elem in test_corpus:\n",
    "    a = list(model.infer_vector(elem))\n",
    "    test_vecs.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(train_vecs, label=train_nums)\n",
    "xg_test = xgb.DMatrix(test_vecs, label=test_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'multi:softmax', 'max_depth': 6, 'silent': 1, 'num_class': 4}\n"
     ]
    }
   ],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['num_class'] = 4\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.102041\ttest-merror:0.376238\n",
      "[1]\ttrain-merror:0.053061\ttest-merror:0.366337\n",
      "[2]\ttrain-merror:0.026531\ttest-merror:0.346535\n",
      "[3]\ttrain-merror:0.012245\ttest-merror:0.346535\n",
      "[4]\ttrain-merror:0.010204\ttest-merror:0.346535\n",
      "[5]\ttrain-merror:0.010204\ttest-merror:0.346535\n",
      "[6]\ttrain-merror:0.002041\ttest-merror:0.366337\n",
      "[7]\ttrain-merror:0.002041\ttest-merror:0.376238\n",
      "[8]\ttrain-merror:0\ttest-merror:0.376238\n",
      "[9]\ttrain-merror:0\ttest-merror:0.376238\n",
      "Test error using softmax = 0.00909090909090909\n",
      "[0]\ttrain-merror:0.102041\ttest-merror:0.376238\n",
      "[1]\ttrain-merror:0.053061\ttest-merror:0.366337\n",
      "[2]\ttrain-merror:0.026531\ttest-merror:0.346535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MichaelK/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-merror:0.012245\ttest-merror:0.346535\n",
      "[4]\ttrain-merror:0.010204\ttest-merror:0.346535\n",
      "[5]\ttrain-merror:0.010204\ttest-merror:0.346535\n",
      "[6]\ttrain-merror:0.002041\ttest-merror:0.366337\n",
      "[7]\ttrain-merror:0.002041\ttest-merror:0.376238\n",
      "[8]\ttrain-merror:0\ttest-merror:0.376238\n",
      "[9]\ttrain-merror:0\ttest-merror:0.376238\n",
      "Test error using softprob = 0.009900990099009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MichaelK/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "pred = bst.predict(xg_test)\n",
    "error_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))\n",
    "\n",
    "# do the same thing again, but output probabilities\n",
    "param['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# Note: this convention has been changed since xgboost-unity\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "pred_prob = bst.predict(xg_test)#.reshape(np.array(test_labels).shape[0], 6)\n",
    "pred_label = np.argmax(pred_prob, axis=1)\n",
    "error_rate = np.sum(pred != test_labels) / np.array(test_labels).shape[0]\n",
    "print('Test error using softprob = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62376237623762376"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state = 12)\n",
    "_ = rdf.fit(train_vecs, train_nums)\n",
    "np.mean(rdf.predict(test_vecs) == test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6633663366336634"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_depth': np.arange(3, 10)}\n",
    "\n",
    "tree = GridSearchCV(DecisionTreeClassifier(random_state = 42, class_weight = 'balanced'), param_grid)\n",
    "\n",
    "tree.fit(train_vecs, train_nums)\n",
    "tree_preds = (tree.predict(test_vecs))\n",
    "np.mean(tree_preds == test_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
